{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8bdc85c",
   "metadata": {},
   "source": [
    "# Relatório e Projeto - Sistema de indexação e busca de documentos\n",
    "\n",
    "## 1 - Informações da equipe\n",
    "---\n",
    "IN1152 - Recuperação Inteligente de Informação - 2022.2\n",
    "\n",
    "**Equipe**: Matheus Rodrigues de Souza Félix (matheusrdgsf@gmail.com) e Rodrigo Souza de Melo (rsm5@cin.ufpe.br)\n",
    "\n",
    "**Projeto \"Sistema de indexação e busca de documentos\"**\n",
    "\n",
    "Professora Flavia de Almeida Barros (fab@cin.ufpe.br)\n",
    "\n",
    "- Este relatório apresentará as seções solicitadas no Trabalho 1 - Sistema de indexação e busca de documentos. E mais abaixo o código-fonte do projeto\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e6786",
   "metadata": {},
   "source": [
    "## 2 - Descrição dos documentos (corpus) que serão indexados pelo sistema\n",
    "---\n",
    "\n",
    " - 2 Temas/tópicos dos documentos da sua base\n",
    " - Mostrar no relatório 2 ou 3 exemplos de documentos do corpus\n",
    " \n",
    " - BEIR [1] é um benchmark heterogêneo contendo diversas tarefas de RI. Ele também fornece uma estrutura comum e fácil para avaliação de seus modelos de recuperação baseados em PNL. Dentre as opções do BEIR foi selecionado o SciFact.\n",
    " - SciFact [4]: Devido ao rápido crescimento da literatura científica, há a necessidade de sistemas automatizados para auxiliar pesquisadores e o público na avaliação da veracidade das afirmações científicas. Para facilitar o desenvolvimento de sistemas para essa tarefa, é utilizado o SciFact, um conjunto de dados de 1,4 mil declarações escritas por especialistas, combinadas com resumos contendo evidências anotados com rótulos e justificativas de veracidade.\n",
    " - Leaderboard [4]: Avalia submissões de modelos no conjunto de dados SciFact, com o objetivo de desenvolver sistemas automatizados para verificação de alegações científicas.\n",
    " - Dataset [2]: Formando pelos elementos abaixo.\n",
    "   - corpus: Representa o título e o texto do documento\n",
    "   - query: Representa a consulta\n",
    "   - qrels: Representa a relevância das consulta(s) realizada(s)\n",
    "   \n",
    " - Exemplo de uma estrutura do documento com 2 queries, 2 documentos e as relevâncias de cada consulta [2].\n",
    "\n",
    "~~~json\n",
    "corpus = {\n",
    "    \"doc1\" : {\n",
    "        \"title\": \"Albert Einstein\", \n",
    "        \"text\": \"Albert Einstein was a German-born theoretical physicist. who developed the theory of relativity, \\\n",
    "                 one of the two pillars of modern physics (alongside quantum mechanics). His work is also known for \\\n",
    "                 its influence on the philosophy of science. He is best known to the general public for his massâ€“energy \\\n",
    "                 equivalence formula E = mc2, which has been dubbed 'the world's most famous equation'. He received the 1921 \\\n",
    "                 Nobel Prize in Physics 'for his services to theoretical physics, and especially for his discovery of the law \\\n",
    "                 of the photoelectric effect', a pivotal step in the development of quantum theory.\"\n",
    "        },\n",
    "    \"doc2\" : {\n",
    "        \"title\": \"\", # Keep title an empty string if not present\n",
    "        \"text\": \"Wheat beer is a top-fermented beer which is brewed with a large proportion of wheat relative to the amount of \\\n",
    "                 malted barley. The two main varieties are German WeiÃŸbier and Belgian witbier; other types include Lambic (made\\\n",
    "                 with wild yeast), Berliner Weisse (a cloudy, sour beer), and Gose (a sour, salty beer).\"\n",
    "    },\n",
    "}\n",
    "\n",
    "queries = {\n",
    "    \"q1\" : \"Who developed the mass-energy equivalence formula?\",\n",
    "    \"q2\" : \"Which beer is brewed with a large proportion of wheat?\"\n",
    "}\n",
    "\n",
    "qrels = {\n",
    "    \"q1\" : {\"doc1\": 1},\n",
    "    \"q2\" : {\"doc2\": 1},\n",
    "}\n",
    "~~~\n",
    " \n",
    " Referências: \n",
    " * [1] https://github.com/beir-cellar/beir\n",
    " * [2] https://huggingface.co/datasets/BeIR/scifact-generated-queries\n",
    " * [3] https://github.com/allenai/scifact\n",
    " * [4] https://leaderboard.allenai.org/scifact/submissions/about\n",
    "              \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004999a",
   "metadata": {},
   "source": [
    "## 3 - Arquitetura do sistema \n",
    "---\n",
    "\n",
    "- Prover uma descrição breve das etapas de processamento do sistema construído com base na ferramenta escolhida. Informar qual é o modelo de RI implementado pelo seu sistema, qual a fórmula para cálculo dos pesos e qual a função de ranking (vejam as aulas de modelos de RI). \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592246a8",
   "metadata": {},
   "source": [
    "## 4 - Criação das bases de documentos indexados \n",
    "---\n",
    "\n",
    "- Preparação & Indexação dos documentos: O sistema deve criar, de forma automática, cinco BASES indexadas a partir da base original de documentos. Cada BASE (no Solr, são COREs) deve utilizar processos diferentes na preparação (pré-processamento) dos dados. O objetivo é verificar qual é a melhor configuração de pré-processamento para o seu caso.\n",
    "\n",
    "   - BASE 1: documentos originais, sem nenhum pré-processamento extra (só tokenização);\n",
    "   - BASE 2: apenas eliminar stopwords (usar filtro de stopwords);\n",
    "   - BASE 3: apenas usar stemming, sem eliminar as stopwords (não usar filtro de stopwords);\n",
    "   - BASE 4: eliminar stopwords (usar filtro de stopwords) e usar stemming;\n",
    "   - BASE 5: eliminar stopwords (usar filtro de stopwords), não usar stemming, e usar dicionário de sinônimos.\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3103f4",
   "metadata": {},
   "source": [
    "## 5 - Criação das consultas e Criação da Matriz de relevância  \n",
    "---\n",
    "\n",
    "- Prover uma descrição breve das etapas de processamento do sistema construído com base na ferramenta escolhida. Informar qual é o modelo de RI implementado pelo seu sistema, qual a fórmula para cálculo dos pesos e qual a função de ranking (vejam as aulas de modelos de RI). \n",
    "\n",
    "- Esta etapa foi descrita em mais detalhes na atividade correspondente, postada no Classroom. \n",
    "  ===> DÚVIDA: NÃO ENCONTREI OS DETALHES NO CLASSROOM.\n",
    "  \n",
    "- Mostrar aqui parte da matriz - basta mostrar as 5 colunas exemplificadas abaixo (incluindo a coluna final com a quantidade de documentos relevantes). \n",
    "\n",
    "Exemplo de Matriz de relevância “Consultas x Documentos”.\n",
    "\n",
    "\n",
    "|                                                                      | Doc 1 | Doc 2 | ... Doc 20 | Qtd de docs relevantes |   |   |   |   |   |\n",
    "|----------------------------------------------------------------------|-------|-------|------------|------------------------|---|---|---|---|---|\n",
    "| Consulta1 Ex.:  como faço o agendamento para tomar vacina de covid ? | 1     | 0     | 1          | 10                     |   |   |   |   |   |\n",
    "| Consulta2 Ex.: Qual o preço de carro FIAT UNO usado ?                     | 1     | 1     | 0          | 15                     |   |   |   |   |   |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b56ca",
   "metadata": {},
   "source": [
    "## 6 - Testes/Avaliação \n",
    "---\n",
    "\n",
    "- Submeter as 2 consultas para cada BASE criada, e avaliar cada resultado separadamente -  i.e., calcular separadamente a precisão e a cobertura de cada consulta em relação a cada BASE criada. \n",
    "- Usar as fórmulas vistas em aula: precisão, cobertura e F-measure. \n",
    "- Incluir no relatório uma matriz de resultados para CADA consulta. Assim podemos ver a influência do pré-processamento dos documentos no resultado final do sistema.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Matriz de resultados para a Consulta 1\n",
    "- Consulta: incluam aqui o texto da consulta avaliada nessa matriz\n",
    "- Qtd de documentos relevantes: ver matriz de relevância (avaliação manual)\n",
    "\n",
    "|  | **Precisão** | **Cobertura** | **F-measure** | **Qtd de Docs relevantes retornados pela  consulta 1** | **Qtd total de documentos retornados pela consulta 1** |\n",
    "|:--------:|:------------:|:-------------:|:-------------:|:------------------------------------------------------:|:------------------------------------------------------:|\n",
    "| BASE 1   |              |               |               |                                                        |                                                        |\n",
    "| BASE 2   |              |               |               |                                                        |                                                        |\n",
    "| BASE 3   |              |               |               |                                                        |                                                        |\n",
    "| BASE 4   |              |               |               |                                                        |                                                        |\n",
    "| BASE 5   |              |               |               |                                                        |                                                        |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Matriz de resultados para a Consulta 2\n",
    "- Consulta: incluam aqui o texto da consulta avaliada nessa matriz\n",
    "- Qtd de documentos relevantes: ver matriz de relevância (avaliação manual)\n",
    "\n",
    "|  | **Precisão** | **Cobertura** | **F-measure** | **Qtd de Docs relevantes retornados pela  consulta 2** | **Qtd total de documentos retornados pela consulta 2** |\n",
    "|:--------:|:------------:|:-------------:|:-------------:|:------------------------------------------------------:|:------------------------------------------------------:|\n",
    "| BASE 1   |              |               |               |                                                        |                                                        |\n",
    "| BASE 2   |              |               |               |                                                        |                                                        |\n",
    "| BASE 3   |              |               |               |                                                        |                                                        |\n",
    "| BASE 4   |              |               |               |                                                        |                                                        |\n",
    "| BASE 5   |              |               |               |                                                        |                                                        |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Matriz de resultados para o Sistema\n",
    "- As medidas de precisão, cobertura e F-meause do sistema serão obtidas calculando-se a média entre os resultados obtidos com cada consulta em relação a cada BASE criado.\n",
    "\n",
    "\n",
    "|        | Precisão média | Cobertura média | F-measure média |\n",
    "|--------|----------------|-----------------|-----------------|\n",
    "| BASE 1 |                |                 |                 |\n",
    "| BASE 2 |                |                 |                 |\n",
    "| BASE 3 |                |                 |                 |\n",
    "| BASE 4 |                |                 |                 |\n",
    "| BASE 5 |                |                 |                 |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f679cfd",
   "metadata": {},
   "source": [
    "## 7 - Conclusão \n",
    "---\n",
    "\n",
    "- Deve conter um texto curto explicando o que vocês concluíram a partir do resultado dos testes (tabelas acima).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d96b6",
   "metadata": {},
   "source": [
    "## Código-fonte do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b2b07",
   "metadata": {},
   "source": [
    "### Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1500d48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GitPython\n",
      "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, gitdb, GitPython\n",
      "Successfully installed GitPython-3.1.27 gitdb-4.0.9 smmap-5.0.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install GitPython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfce8c72",
   "metadata": {},
   "source": [
    "### Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf48fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Matheus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Matheus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from git import Repo\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "import gzip\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report #Utilizado para calcular a matrix de confusão e Relatório de classificação - Checar outra forma para remover o warning e não utilizar o parâmetro zero_division=1 no recall_score \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import unidecode\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from scipy import spatial\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c323c7",
   "metadata": {},
   "source": [
    "### Data Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c8c1267",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"dataset/scifact-generated-queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae5261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(DATA_PATH):\n",
    "    Repo.clone_from(\"https://huggingface.co/datasets/BeIR/scifact-generated-queries\", \"dataset/scifact-generated-queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9567a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(DATA_PATH+\"/train.jsonl.gz\", 'rb') as f:\n",
    "    file_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "408b3272",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json(BytesIO(file_content), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75057d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>queries_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHENIX: a comprehensive Python...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DNA methylation and healthy human aging</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US-SOMO HPLC-SAXS module: dealing with capill...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Grazing\": a high-risk behavior.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Natural\" killer cells in the mouse. I. Cytoto...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5176</th>\n",
       "      <td>β-catenin-independent WNT signaling in basal-l...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5177</th>\n",
       "      <td>β-site amyloid precursor protein-cleaving enzy...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>β1 integrin mediates an alternative survival p...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>‘Short stature in children - a questionnaire f...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5180</th>\n",
       "      <td>“Rapid-Impact Interventions”: How a Policy of ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5181 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  queries_count\n",
       "0                     PHENIX: a comprehensive Python...              3\n",
       "1               DNA methylation and healthy human aging              3\n",
       "2      US-SOMO HPLC-SAXS module: dealing with capill...              3\n",
       "3                      \"Grazing\": a high-risk behavior.              3\n",
       "4     \"Natural\" killer cells in the mouse. I. Cytoto...              3\n",
       "...                                                 ...            ...\n",
       "5176  β-catenin-independent WNT signaling in basal-l...              3\n",
       "5177  β-site amyloid precursor protein-cleaving enzy...              3\n",
       "5178  β1 integrin mediates an alternative survival p...              3\n",
       "5179  ‘Short stature in children - a questionnaire f...              3\n",
       "5180  “Rapid-Impact Interventions”: How a Policy of ...              3\n",
       "\n",
       "[5181 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby([\"title\"]).size().reset_index(name='queries_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c9b7f",
   "metadata": {},
   "source": [
    "## Pre-rocesing Data\n",
    "\n",
    "In this step we will create 5 data models:\n",
    "\n",
    "v1 - Only Tokenization; \\\n",
    "v2 - Only Stopword Filter; \\\n",
    "v3 - Only Stemming; \\\n",
    "v4 - Remove Stopwords and Stemming; \\\n",
    "v5 - Remove Stopworpd and expand words with Synonyms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37629bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accent(text):\n",
    "    return unidecode.unidecode(text)\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text, language=\"english\")\n",
    "\n",
    "def pre_process(text, rmv_sw, stem):\n",
    "    text_lower = text.lower()\n",
    "    text_rmv_accent = remove_accent(text_lower)\n",
    "    text_final = tokenize(text_rmv_accent)\n",
    "    \n",
    "    if rmv_sw:\n",
    "        text_final = list(filter(lambda token: token not in STOPWORDS, text_final))\n",
    "    \n",
    "    if stem:\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        text_final = list(map(lambda token: stemmer.stem(token), text_final))\n",
    "        \n",
    "    return text_final\n",
    "\n",
    "STOPWORDS = set(map(lambda token: remove_accent(token), stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87c94be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process_v1 = lambda text: pre_process(text, False, False)\n",
    "pre_process_v2 = lambda text: pre_process(text, True, False)\n",
    "pre_process_v3 = lambda text: pre_process(text, False, True)\n",
    "pre_process_v4 = lambda text: pre_process(text, True, True)\n",
    "#pre_process_v5 = lambda i: pre_process(text, True, False) # TODO: Para este caso eu chequei esta referência -> https://www.holisticseo.digital/python-seo/nltk/wordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75283f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pcrs = dataset.copy().drop(\"query\", axis=1).drop_duplicates().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e714b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pcrs[\"v1\"] = dataset_pcrs[\"text\"].apply(lambda text: pre_process_v1(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "252a864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pcrs[\"v2\"] = dataset_pcrs[\"text\"].apply(lambda text: pre_process_v2(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91ab5f48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_pcrs[\"v3\"] = dataset_pcrs[\"text\"].apply(lambda text: pre_process_v3(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "517208ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pcrs[\"v4\"] = dataset_pcrs[\"text\"].apply(lambda text: pre_process_v4(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43c9b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO: Create Expand Vocabulary Pipeline add connect pre_process\n",
    "# dataset_pcrs[\"v5\"] = dataset_pcrs[\"text\"].apply(lambda text: pre_process_v5(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0c7d265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4983</td>\n",
       "      <td>Microstructural development of human newborn c...</td>\n",
       "      <td>Alterations of the architecture of cerebral wh...</td>\n",
       "      <td>[alterations, of, the, architecture, of, cereb...</td>\n",
       "      <td>[alterations, architecture, cerebral, white, m...</td>\n",
       "      <td>[alter, of, the, architectur, of, cerebr, whit...</td>\n",
       "      <td>[alter, architectur, cerebr, white, matter, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5836</td>\n",
       "      <td>Induction of myelodysplasia by myeloid-derived...</td>\n",
       "      <td>Myelodysplastic syndromes (MDS) are age-depend...</td>\n",
       "      <td>[myelodysplastic, syndromes, (, mds, ), are, a...</td>\n",
       "      <td>[myelodysplastic, syndromes, (, mds, ), age-de...</td>\n",
       "      <td>[myelodysplast, syndrom, (, mds, ), are, age-d...</td>\n",
       "      <td>[myelodysplast, syndrom, (, mds, ), age-depend...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _id                                              title  \\\n",
       "0  4983  Microstructural development of human newborn c...   \n",
       "3  5836  Induction of myelodysplasia by myeloid-derived...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Alterations of the architecture of cerebral wh...   \n",
       "3  Myelodysplastic syndromes (MDS) are age-depend...   \n",
       "\n",
       "                                                  v1  \\\n",
       "0  [alterations, of, the, architecture, of, cereb...   \n",
       "3  [myelodysplastic, syndromes, (, mds, ), are, a...   \n",
       "\n",
       "                                                  v2  \\\n",
       "0  [alterations, architecture, cerebral, white, m...   \n",
       "3  [myelodysplastic, syndromes, (, mds, ), age-de...   \n",
       "\n",
       "                                                  v3  \\\n",
       "0  [alter, of, the, architectur, of, cerebr, whit...   \n",
       "3  [myelodysplast, syndrom, (, mds, ), are, age-d...   \n",
       "\n",
       "                                                  v4  \n",
       "0  [alter, architectur, cerebr, white, matter, de...  \n",
       "3  [myelodysplast, syndrom, (, mds, ), age-depend...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Be careful with dataset_pcrs Len\n",
    "#HTML(dataset_pcrs.head(3).to_html())\n",
    "\n",
    "# @TODO: add \"()\" to STOPWORDS. A better strategy is create a dict simbol to filter and add this pipeline.\n",
    "dataset_pcrs.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489658fb",
   "metadata": {},
   "source": [
    "### Vectorizing Data\n",
    "\n",
    "This step defines 5 (vectorizer, corpus_vetorized) models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d182078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documments(df_column):\n",
    "    return list(map(lambda tokenized_text: \" \".join(tokenized_text), df_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57d9c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_v1 = get_documments(dataset_pcrs[\"v1\"])\n",
    "corpus_v2 = get_documments(dataset_pcrs[\"v2\"])\n",
    "corpus_v3 = get_documments(dataset_pcrs[\"v3\"])\n",
    "corpus_v4 = get_documments(dataset_pcrs[\"v4\"])\n",
    "# corpus_v5 = get_documments(dataset_pcrs[\"v5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8573ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_v1 = TfidfVectorizer()\n",
    "corpus_v1_vct = vectorizer_v1.fit_transform(corpus_v1)\n",
    "\n",
    "vectorizer_v2 = TfidfVectorizer()\n",
    "corpus_v2_vct = vectorizer_v2.fit_transform(corpus_v2)\n",
    "\n",
    "vectorizer_v3 = TfidfVectorizer()\n",
    "corpus_v3_vct = vectorizer_v3.fit_transform(corpus_v3)\n",
    "\n",
    "vectorizer_v4 = TfidfVectorizer()\n",
    "corpus_v4_vct = vectorizer_v4.fit_transform(corpus_v4)\n",
    "\n",
    "# vectorizer_v5 = TfidfVectorizer()\n",
    "# corpus_v1_vct = vectorizer_v5.fit_transform(corpus_v5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda70a07",
   "metadata": {},
   "source": [
    "### Retrieval Information Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c610c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kd -> KDTree, nn -> Nearest Neighbor, bf -> Brute Force\n",
    "# n -> number of docs in return, use -1 to all docs\n",
    "def info_retrieval(pre_process, corpus, vectorizer, query, n=2, matcher=\"kd\"):\n",
    "    \n",
    "    query = \" \".join(pre_process(query))\n",
    "    query_vct = vectorizer.transform([query])\n",
    "    \n",
    "    if n == -1:\n",
    "        \n",
    "        n = corpus.shape[0]\n",
    "    \n",
    "    if matcher == \"kd\":\n",
    "        \n",
    "        kdtree = scipy.spatial.KDTree(corpus_v1_vct.todense())\n",
    "        \n",
    "        # p is Minkowski p-norm.\n",
    "        # p = 1, Manhattan Distance\n",
    "        # p = 2, Euclidean Distance\n",
    "        # p = +inf, Chebychev Distance\n",
    "        distance, index = kdtree.query(query_vct.todense(), n, p=1)\n",
    "        \n",
    "    elif matcher == \"nn\":\n",
    "        \n",
    "        nbrs = NearestNeighbors(n_neighbors=n, algorithm=\"ball_tree\").fit(corpus)\n",
    "        distance, index = nbrs.kneighbors(query_vct)\n",
    "        \n",
    "    elif matcher == \"bf\":\n",
    "\n",
    "        nbrs = NearestNeighbors(n_neighbors=n, algorithm=\"brute\", metric=\"cosine\").fit(corpus)\n",
    "        distance, index = nbrs.kneighbors(query_vct)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        return \"Matcher strategy not avaliable. Set kd to KDTree, nn to Nearest Neighbor and bf to Brute Force\"\n",
    "    \n",
    "    return list(zip(distance.tolist()[0], index.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4383e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_v1 = lambda query: info_retrieval(pre_process_v1, corpus_v1_vct, vectorizer_v1, query, n=-1, matcher = \"bf\")\n",
    "ir_v2 = lambda query: info_retrieval(pre_process_v2, corpus_v2_vct, vectorizer_v2, query, n=-1, matcher = \"bf\")\n",
    "ir_v3 = lambda query: info_retrieval(pre_process_v3, corpus_v3_vct, vectorizer_v3, query, n=-1, matcher = \"bf\")\n",
    "ir_v4 = lambda query: info_retrieval(pre_process_v4, corpus_v4_vct, vectorizer_v4, query, n=-1, matcher = \"bf\")\n",
    "# ir_v5 = lambda query: info_retrieval(pre_process_v5, corpus_v5_vct, vectorizer_v5, query, n=-1, matcher = \"bf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590be1bc",
   "metadata": {},
   "source": [
    "### Snippet Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82e66307",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Alterations of the architecture of cerebral white matter in the developing human brain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb86c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sorted(ir_v1(query), key=lambda i:i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5357961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5512980389649619, 0),\n",
       " (0.9018937692186384, 4),\n",
       " (0.9030226639226278, 8),\n",
       " (0.904491849656119, 22),\n",
       " (0.9045364304922894, 3),\n",
       " (0.9055550155037727, 15),\n",
       " (0.9059548306703978, 40),\n",
       " (0.9107837002564602, 23),\n",
       " (0.9180953622326151, 7),\n",
       " (0.9188460324359904, 10),\n",
       " (0.9197344396945608, 37),\n",
       " (0.9204179861579849, 26),\n",
       " (0.9209788244798877, 47),\n",
       " (0.924605936837051, 34),\n",
       " (0.9257283763325889, 14),\n",
       " (0.9301273361039335, 46),\n",
       " (0.930343144950218, 20),\n",
       " (0.9307127649225015, 25),\n",
       " (0.9309219855750911, 36),\n",
       " (0.9310791524131075, 17),\n",
       " (0.9323432398604214, 21),\n",
       " (0.9333678935374439, 42),\n",
       " (0.9347401841822083, 30),\n",
       " (0.9375193526919786, 6),\n",
       " (0.9380836793410617, 24),\n",
       " (0.9438240485634083, 29),\n",
       " (0.9438526522441384, 33),\n",
       " (0.9448974986965711, 1),\n",
       " (0.9451534537521332, 31),\n",
       " (0.945777795071706, 27),\n",
       " (0.9465581953663532, 13),\n",
       " (0.9472385587498705, 45),\n",
       " (0.9495743997281749, 2),\n",
       " (0.9497327886616467, 5),\n",
       " (0.9499669994122191, 44),\n",
       " (0.950751768678862, 28),\n",
       " (0.9521823112364727, 32),\n",
       " (0.9523517911829948, 43),\n",
       " (0.9545493851186811, 41),\n",
       " (0.9546771015512568, 9),\n",
       " (0.9558180117821312, 11),\n",
       " (0.9559451637582027, 38),\n",
       " (0.9574216094551308, 35),\n",
       " (0.9603206219248321, 16),\n",
       " (0.9615924561868899, 39),\n",
       " (0.9639090554631371, 48),\n",
       " (0.9680065228057593, 49),\n",
       " (0.9696280094304914, 18),\n",
       " (0.9710623396735132, 12),\n",
       " (0.9714501756438524, 19)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cd70023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4983"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nearest Documment to Query Snippet\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "result_nn = result[0][1]\n",
    "dataset_pcrs[[\"_id\", \"title\", \"text\"]].iloc[[result_nn]][\"_id\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9692de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639f6be5",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cc4a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar Function to Get ID of nearest documment to specified query.\n",
    "def get_nearest_id(query, model, data):\n",
    "    result = sorted(model(query), key=lambda i:i[0])\n",
    "    result_nn = result[0][1]\n",
    "    return int(data[[\"_id\"]].iloc[[result_nn]][\"_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a6223e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>54440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>70115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>70490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>72159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>79447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>87758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>92308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>92499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>97884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>102662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>103007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>104130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>106301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>116792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>118568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>120626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>123859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>140874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>143251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>152245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>153744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>159469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>164189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>164985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>169264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>175735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>188911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>195352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>202259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>207972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>213017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>219475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>226488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>236204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>238409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>243694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>253672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>263364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>266641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>275294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>279052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>285794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>293661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        _id\n",
       "0      4983\n",
       "3      5836\n",
       "6      7912\n",
       "9     18670\n",
       "12    19238\n",
       "15    33370\n",
       "18    36474\n",
       "21    54440\n",
       "24    70115\n",
       "27    70490\n",
       "30    72159\n",
       "33    79447\n",
       "36    87758\n",
       "39    92308\n",
       "42    92499\n",
       "45    97884\n",
       "48   102662\n",
       "51   103007\n",
       "54   104130\n",
       "57   106301\n",
       "60   116792\n",
       "63   118568\n",
       "66   120626\n",
       "69   123859\n",
       "72   140874\n",
       "75   143251\n",
       "78   152245\n",
       "81   153744\n",
       "84   159469\n",
       "86   164189\n",
       "89   164985\n",
       "92   169264\n",
       "95   175735\n",
       "98   188911\n",
       "101  195352\n",
       "104  202259\n",
       "107  207972\n",
       "110  213017\n",
       "113  219475\n",
       "116  226488\n",
       "119  236204\n",
       "122  238409\n",
       "125  243694\n",
       "128  253672\n",
       "131  263364\n",
       "134  266641\n",
       "137  275294\n",
       "140  279052\n",
       "143  285794\n",
       "146  293661"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pcrs[[\"_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4d750e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used_ids -> flag if we used some batch in dataset_pcrs in development\n",
    "used_ids = dataset_pcrs[\"_id\"].tolist()\n",
    "ds_eval = dataset[dataset[\"_id\"].isin(used_ids)].drop([\"text\"], axis=1).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcca499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_eval[\"ir_v1_nn\"] = ds_eval[\"query\"].apply(lambda query: get_nearest_id(query, ir_v1, dataset_pcrs))\n",
    "ds_eval[\"ir_v2_nn\"] = ds_eval[\"query\"].apply(lambda query: get_nearest_id(query, ir_v2, dataset_pcrs))\n",
    "ds_eval[\"ir_v3_nn\"] = ds_eval[\"query\"].apply(lambda query: get_nearest_id(query, ir_v3, dataset_pcrs))\n",
    "ds_eval[\"ir_v4_nn\"] = ds_eval[\"query\"].apply(lambda query: get_nearest_id(query, ir_v4, dataset_pcrs))\n",
    "#ds_eval[\"ir_v5_nn\"] = ds_eval_v1[\"query\"].apply(lambda i: get_nearest_id(query, ir_v5, dataset_pcrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96b33648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>query</th>\n",
       "      <th>ir_v1_nn</th>\n",
       "      <th>ir_v2_nn</th>\n",
       "      <th>ir_v3_nn</th>\n",
       "      <th>ir_v4_nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4983</td>\n",
       "      <td>Microstructural development of human newborn c...</td>\n",
       "      <td>what is the diffusion coefficient of cerebral ...</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4983</td>\n",
       "      <td>Microstructural development of human newborn c...</td>\n",
       "      <td>what is diffusion tensor</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4983</td>\n",
       "      <td>Microstructural development of human newborn c...</td>\n",
       "      <td>what is the diffusion coefficient of the cereb...</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5836</td>\n",
       "      <td>Induction of myelodysplasia by myeloid-derived...</td>\n",
       "      <td>which type of hematopoiesis is characterized b...</td>\n",
       "      <td>5836</td>\n",
       "      <td>5836</td>\n",
       "      <td>5836</td>\n",
       "      <td>5836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5836</td>\n",
       "      <td>Induction of myelodysplasia by myeloid-derived...</td>\n",
       "      <td>which cell types have hematopoiesis</td>\n",
       "      <td>5836</td>\n",
       "      <td>5836</td>\n",
       "      <td>5836</td>\n",
       "      <td>5836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _id                                              title  \\\n",
       "0  4983  Microstructural development of human newborn c...   \n",
       "1  4983  Microstructural development of human newborn c...   \n",
       "2  4983  Microstructural development of human newborn c...   \n",
       "3  5836  Induction of myelodysplasia by myeloid-derived...   \n",
       "4  5836  Induction of myelodysplasia by myeloid-derived...   \n",
       "\n",
       "                                               query  ir_v1_nn  ir_v2_nn  \\\n",
       "0  what is the diffusion coefficient of cerebral ...      4983      4983   \n",
       "1                           what is diffusion tensor      4983      4983   \n",
       "2  what is the diffusion coefficient of the cereb...      4983      4983   \n",
       "3  which type of hematopoiesis is characterized b...      5836      5836   \n",
       "4                which cell types have hematopoiesis      5836      5836   \n",
       "\n",
       "   ir_v3_nn  ir_v4_nn  \n",
       "0      4983      4983  \n",
       "1      4983      4983  \n",
       "2      4983      4983  \n",
       "3      5836      5836  \n",
       "4      5836      5836  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_eval.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6db9fc88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# @TODO: add ir_v5_nn\n",
    "eval_models = {\"model\": [\"ir_v1_nn\",\"ir_v2_nn\",\"ir_v3_nn\",\"ir_v4_nn\"],\n",
    "               \"precision\": [], \"recall\": [], \"f-measure\": []}\n",
    "\n",
    "for model in eval_models[\"model\"]:\n",
    "    \n",
    "    y_true = list(map(lambda i: int(i), ds_eval[\"_id\"].tolist()))\n",
    "    y_pred = list(map(lambda i: int(i), ds_eval[model].tolist()))\n",
    "    \n",
    "    \n",
    "    eval_models[\"precision\"].append(precision_score(y_true, y_pred, average='weighted'))\n",
    "    \n",
    "    #Old\n",
    "    #eval_models[\"recall\"].append(recall_score(y_true, y_pred, average='weighted'))\n",
    "    #Test -> Mesmo removendo o warning, o resultado deu o mesmo ao imprimir o resultado dos métodos.\n",
    "    \n",
    "    eval_models[\"recall\"].append(recall_score(y_true, y_pred, average='weighted', zero_division=1))\n",
    "    \n",
    "    eval_models[\"f-measure\"].append(f1_score(y_true, y_pred, average='weighted'))\n",
    "    \n",
    "    #Sugestão avaliar a matrix de confusão e o relatório de classificação para verificar como alterar o modelo.\n",
    "    # print(confusion_matrix(y_true,y_pred))\n",
    "    # print(classification_report(y_true,y_pred))\n",
    "    \n",
    "    '''\n",
    "    Alteração no código -> eval_models[\"recall\"].append(recall_score(y_true, y_pred, average='weighted', zero_division=1))\n",
    "         Foi apenas adicionado o parâmetro \"zero_division=1\"\n",
    "\n",
    "\n",
    "         Fonte: https://stackoverflow.com/questions/68534836/warning-precision-and-f-score-are-ill-defined-and-being-set-to-0-0-in-labels-wi\n",
    "                https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5b13fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(eval_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47db6661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f-measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ir_v1_nn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ir_v2_nn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ir_v3_nn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ir_v4_nn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  precision  recall  f-measure\n",
       "0  ir_v1_nn        1.0    1.00      1.000\n",
       "1  ir_v2_nn        1.0    1.00      1.000\n",
       "2  ir_v3_nn        1.0    0.96      0.976\n",
       "3  ir_v4_nn        1.0    0.96      0.976"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb52b87",
   "metadata": {},
   "source": [
    "## 20-News Dataset Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9c3045cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "cats = ['alt.atheism', 'soc.religion.christian']\n",
    "newsgroups_train = fetch_20newsgroups(data_home=\"dataset/20_newgroup\", subset='train', remove=('headers', 'footers', 'quotes'), download_if_missing=True, categories=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8161139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.Series(newsgroups_train.data)\n",
    "data=pd.DataFrame(data)\n",
    "data.columns = ['text']\n",
    "data['target'] = pd.Series(newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b62583b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Library of Congress to Host Dead Sea Scroll Symposium April 21-22 To: National and Assignment desks, Daybook Editor Contact: John Sullivan, 202-707-9216, or Lucy Suddreth, 202-707-9191          both of the Library of Congress   WASHINGTON, April 19  -- A symposium on the Dead Sea Scrolls will be held at the Library of Congress on Wednesday,April 21, and Thursday, April 22.  The two-day program, cosponsoredby the library and Baltimore Hebrew University, with additionalsupport from the Project Judaica Foundation, will be held in thelibrary's Mumford Room, sixth floor, Madison Building.   Seating is limited, and admission to any session of the symposiummust be requested in writing (see Note A).   The symposium will be held one week before the public opening of amajor exhibition, \"Scrolls from the Dead Sea: The Ancient Library ofQumran and Modern Scholarship,\" that opens at the Library of Congresson April 29.  On view will be fragmentary scrolls and archaeologicalartifacts excavated at Qumran, on loan from the Israel AntiquitiesAuthority.  Approximately 50 items from Library of Congress specialcollections will augment these materials.  The exhibition, on view inthe Madison Gallery, through Aug. 1, is made possible by a generousgift from the Project Judaica Foundation of Washington, D.C.   The Dead Sea Scrolls have been the focus of public and scholarlyinterest since 1947, when they were discovered in the desert 13 mileseast of Jerusalem.  The symposium will explore the origin and meaningof the scrolls and current scholarship.  Scholars from diverseacademic backgrounds and religious affiliations, will offer theirdisparate views, ensuring a lively discussion.   The symposium schedule includes opening remarks on April 21, at2 p.m., by Librarian of Congress James H. Billington, and byDr. Norma Furst, president, Baltimore Hebrew University.  Co-chairingthe symposium are Joseph Baumgarten, professor of Rabbinic Literatureand Institutions, Baltimore Hebrew University and Michael Grunberger,head, Hebraic Section, Library of Congress.   Geza Vermes, professor emeritus of Jewish studies, OxfordUniversity, will give the keynote address on the current state ofscroll research, focusing on where we stand today. On the secondday, the closing address will be given by Shmaryahu Talmon, who willpropose a research agenda, picking up the theme of how the Qumranstudies might proceed.   On Wednesday, April 21, other speakers will include:   -- Eugene Ulrich, professor of Hebrew Scriptures, University ofNotre Dame and chief editor, Biblical Scrolls from Qumran, on \"TheBible at Qumran;\"   -- Michael Stone, National Endowment for the Humanitiesdistinguished visiting professor of religious studies, University ofRichmond, on \"The Dead Sea Scrolls and the Pseudepigrapha.\"   -- From 5 p.m. to 6:30 p.m. a special preview of the exhibitionwill be given to symposium participants and guests.   On Thursday, April 22, beginning at 9 a.m., speakers will include:   -- Magen Broshi, curator, shrine of the Book, Israel Museum,Jerusalem, on \"Qumran: The Archaeological Evidence;\"   -- P. Kyle McCarter, Albright professor of Biblical and ancientnear Eastern studies, The Johns Hopkins University, on \"The CopperScroll;\"   -- Lawrence H. Schiffman, professor of Hebrew and Judaic studies,New York University, on \"The Dead Sea Scrolls and the History ofJudaism;\" and   -- James VanderKam, professor of theology, University of NotreDame, on \"Messianism in the Scrolls and in Early Christianity.\"   The Thursday afternoon sessions, at 1:30 p.m., include:   -- Devorah Dimant, associate professor of Bible and Ancient JewishThought, University of Haifa, on \"Qumran Manuscripts: Library of aJewish Community;\"   -- Norman Golb, Rosenberger professor of Jewish history andcivilization, Oriental Institute, University of Chicago, on \"TheCurrent Status of the Jerusalem Origin of the Scrolls;\"   -- Shmaryahu Talmon, J.L. Magnas professor emeritus of Biblicalstudies, Hebrew University, Jerusalem, on \"The Essential 'Commune ofthe Renewed Covenant': How Should Qumran Studies Proceed?\" will closethe symposium.   There will be ample time for question and answer periods at theend of each session.   Also on Wednesday, April 21, at 11 a.m.:   The Library of Congress and The Israel Antiquities Authoritywill hold a lecture by Esther Boyd-Alkalay, consulting conservator,Israel Antiquities Authority, on \"Preserving the Dead Sea Scrolls\"in the Mumford Room, LM-649, James Madison Memorial Building, TheLibrary of Congress, 101 Independence Ave., S.E., Washington, D.C.    ------   NOTE A: For more information about admission to the symposium,please contact, in writing, Dr. Michael Grunberger, head, HebraicSection, African and Middle Eastern Division, Library of Congress,Washington, D.C. 20540. -30-</td>\n",
       "      <td>christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anyone who dies for a \"cause\" runs the risk of dying for a lie.  As forpeople being able to tell if he was a liar, well, we've had grifters andcharlatans since the beginning of civilization.  If David Copperfield hadbeen the Messiah, I bet he could have found plenty of believers.  Jesus was hardly the first to claim to be a faith healer, and he wasn't thefirst to be \"witnessed.\"  What sets him apart?Rubbish.  Nations have followed crazies, liars, psychopaths, and megalomaniacs throughout history.  Hitler, Tojo, Mussolini, Khomeini,Qadaffi, Stalin, Papa Doc, and Nixon come to mind...all from this century.Koresh is a non-issue.Take a discrete mathematics or formal logic course.  There are flaws in yourlogic everywhere.  And as I'm sure others will tell you, read the FAQ!Of course, you have to believe the Bible first.  Just because something iswritten in the Bible does not mean it is true, and the age of that tome plusthe lack of external supporting evidence makes it less credible.  So if youdo quote from the Bible in the future, try to back up that quote with supporting evidence.  Otherwise, you will get flamed mercilessly.Just like weight lifting or guitar playing, eh?  I don't know how you define the world \"total,\" but I would imagine a \"total sacrafice [sp]of everything for God's sake\" would involve more than a time commitment.You are correct about our tendency to \"box everything into time units.\"Would you explain HOW one should involove God in sports and (hehehe)television?</td>\n",
       "      <td>christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Woah...The context is about God's calling out a special people (the Jews) tocarry the \"promise.\"  To read the meaning as literal people is to miss Paul'sentire point.  I'd be glad to send anyone more detailed explanations of thispassage if interested.</td>\n",
       "      <td>christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>See, there you go again, saying that a moral act is only significantif it is \"voluntary.\"  Why do you think this?And anyway, humans have the ability to disregard some of their instincts.You are attaching too many things to the term \"moral,\" I think.Let's try this:  is it \"good\" that animals of the same speciesdon't kill each other.  Or, do you think this is right? Or do you think that animals are machines, and that nothing they dois either right nor wrong?Those weren't arbitrary killings.  They were slayings related to some sortof mating ritual or whatnot.Yes it was, but I still don't understand your distinctions.  Whatdo you mean by \"consider?\"  Can a small child be moral?  How abouta gorilla?  A dolphin?  A platypus?  Where is the line drawn?  Doesthe being need to be self aware?What *do* you call the mechanism which seems to prevent animals ofthe same species from (arbitrarily) killing each other?  Don'tyou find the fact that they don't at all significant?</td>\n",
       "      <td>christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The last sentence is ironic, since so many readers ofsoc.religion.christian seem to not be embarrassed by apologists such asJosh McDowell and C.S. Lewis. The above also expresses a rather odd senseof history. What makes you think the masses in Aquinas' day, who weremostly illiterate, knew any more about rhetoric and logic than most peopletoday? If writings from the period seem elevated consider that only thecream of the crop, so to speak, could read and write. If everyone inthe medieval period \"knew the rules\" it was a matter of uncriticallyaccepting what they were told.Bill Mayne</td>\n",
       "      <td>christian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \\\n",
       "0  Library of Congress to Host Dead Sea Scroll Symposium April 21-22 To: National and Assignment desks, Daybook Editor Contact: John Sullivan, 202-707-9216, or Lucy Suddreth, 202-707-9191          both of the Library of Congress   WASHINGTON, April 19  -- A symposium on the Dead Sea Scrolls will be held at the Library of Congress on Wednesday,April 21, and Thursday, April 22.  The two-day program, cosponsoredby the library and Baltimore Hebrew University, with additionalsupport from the Project Judaica Foundation, will be held in thelibrary's Mumford Room, sixth floor, Madison Building.   Seating is limited, and admission to any session of the symposiummust be requested in writing (see Note A).   The symposium will be held one week before the public opening of amajor exhibition, \"Scrolls from the Dead Sea: The Ancient Library ofQumran and Modern Scholarship,\" that opens at the Library of Congresson April 29.  On view will be fragmentary scrolls and archaeologicalartifacts excavated at Qumran, on loan from the Israel AntiquitiesAuthority.  Approximately 50 items from Library of Congress specialcollections will augment these materials.  The exhibition, on view inthe Madison Gallery, through Aug. 1, is made possible by a generousgift from the Project Judaica Foundation of Washington, D.C.   The Dead Sea Scrolls have been the focus of public and scholarlyinterest since 1947, when they were discovered in the desert 13 mileseast of Jerusalem.  The symposium will explore the origin and meaningof the scrolls and current scholarship.  Scholars from diverseacademic backgrounds and religious affiliations, will offer theirdisparate views, ensuring a lively discussion.   The symposium schedule includes opening remarks on April 21, at2 p.m., by Librarian of Congress James H. Billington, and byDr. Norma Furst, president, Baltimore Hebrew University.  Co-chairingthe symposium are Joseph Baumgarten, professor of Rabbinic Literatureand Institutions, Baltimore Hebrew University and Michael Grunberger,head, Hebraic Section, Library of Congress.   Geza Vermes, professor emeritus of Jewish studies, OxfordUniversity, will give the keynote address on the current state ofscroll research, focusing on where we stand today. On the secondday, the closing address will be given by Shmaryahu Talmon, who willpropose a research agenda, picking up the theme of how the Qumranstudies might proceed.   On Wednesday, April 21, other speakers will include:   -- Eugene Ulrich, professor of Hebrew Scriptures, University ofNotre Dame and chief editor, Biblical Scrolls from Qumran, on \"TheBible at Qumran;\"   -- Michael Stone, National Endowment for the Humanitiesdistinguished visiting professor of religious studies, University ofRichmond, on \"The Dead Sea Scrolls and the Pseudepigrapha.\"   -- From 5 p.m. to 6:30 p.m. a special preview of the exhibitionwill be given to symposium participants and guests.   On Thursday, April 22, beginning at 9 a.m., speakers will include:   -- Magen Broshi, curator, shrine of the Book, Israel Museum,Jerusalem, on \"Qumran: The Archaeological Evidence;\"   -- P. Kyle McCarter, Albright professor of Biblical and ancientnear Eastern studies, The Johns Hopkins University, on \"The CopperScroll;\"   -- Lawrence H. Schiffman, professor of Hebrew and Judaic studies,New York University, on \"The Dead Sea Scrolls and the History ofJudaism;\" and   -- James VanderKam, professor of theology, University of NotreDame, on \"Messianism in the Scrolls and in Early Christianity.\"   The Thursday afternoon sessions, at 1:30 p.m., include:   -- Devorah Dimant, associate professor of Bible and Ancient JewishThought, University of Haifa, on \"Qumran Manuscripts: Library of aJewish Community;\"   -- Norman Golb, Rosenberger professor of Jewish history andcivilization, Oriental Institute, University of Chicago, on \"TheCurrent Status of the Jerusalem Origin of the Scrolls;\"   -- Shmaryahu Talmon, J.L. Magnas professor emeritus of Biblicalstudies, Hebrew University, Jerusalem, on \"The Essential 'Commune ofthe Renewed Covenant': How Should Qumran Studies Proceed?\" will closethe symposium.   There will be ample time for question and answer periods at theend of each session.   Also on Wednesday, April 21, at 11 a.m.:   The Library of Congress and The Israel Antiquities Authoritywill hold a lecture by Esther Boyd-Alkalay, consulting conservator,Israel Antiquities Authority, on \"Preserving the Dead Sea Scrolls\"in the Mumford Room, LM-649, James Madison Memorial Building, TheLibrary of Congress, 101 Independence Ave., S.E., Washington, D.C.    ------   NOTE A: For more information about admission to the symposium,please contact, in writing, Dr. Michael Grunberger, head, HebraicSection, African and Middle Eastern Division, Library of Congress,Washington, D.C. 20540. -30-   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Anyone who dies for a \"cause\" runs the risk of dying for a lie.  As forpeople being able to tell if he was a liar, well, we've had grifters andcharlatans since the beginning of civilization.  If David Copperfield hadbeen the Messiah, I bet he could have found plenty of believers.  Jesus was hardly the first to claim to be a faith healer, and he wasn't thefirst to be \"witnessed.\"  What sets him apart?Rubbish.  Nations have followed crazies, liars, psychopaths, and megalomaniacs throughout history.  Hitler, Tojo, Mussolini, Khomeini,Qadaffi, Stalin, Papa Doc, and Nixon come to mind...all from this century.Koresh is a non-issue.Take a discrete mathematics or formal logic course.  There are flaws in yourlogic everywhere.  And as I'm sure others will tell you, read the FAQ!Of course, you have to believe the Bible first.  Just because something iswritten in the Bible does not mean it is true, and the age of that tome plusthe lack of external supporting evidence makes it less credible.  So if youdo quote from the Bible in the future, try to back up that quote with supporting evidence.  Otherwise, you will get flamed mercilessly.Just like weight lifting or guitar playing, eh?  I don't know how you define the world \"total,\" but I would imagine a \"total sacrafice [sp]of everything for God's sake\" would involve more than a time commitment.You are correct about our tendency to \"box everything into time units.\"Would you explain HOW one should involove God in sports and (hehehe)television?   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Woah...The context is about God's calling out a special people (the Jews) tocarry the \"promise.\"  To read the meaning as literal people is to miss Paul'sentire point.  I'd be glad to send anyone more detailed explanations of thispassage if interested.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        See, there you go again, saying that a moral act is only significantif it is \"voluntary.\"  Why do you think this?And anyway, humans have the ability to disregard some of their instincts.You are attaching too many things to the term \"moral,\" I think.Let's try this:  is it \"good\" that animals of the same speciesdon't kill each other.  Or, do you think this is right? Or do you think that animals are machines, and that nothing they dois either right nor wrong?Those weren't arbitrary killings.  They were slayings related to some sortof mating ritual or whatnot.Yes it was, but I still don't understand your distinctions.  Whatdo you mean by \"consider?\"  Can a small child be moral?  How abouta gorilla?  A dolphin?  A platypus?  Where is the line drawn?  Doesthe being need to be self aware?What *do* you call the mechanism which seems to prevent animals ofthe same species from (arbitrarily) killing each other?  Don'tyou find the fact that they don't at all significant?   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          The last sentence is ironic, since so many readers ofsoc.religion.christian seem to not be embarrassed by apologists such asJosh McDowell and C.S. Lewis. The above also expresses a rather odd senseof history. What makes you think the masses in Aquinas' day, who weremostly illiterate, knew any more about rhetoric and logic than most peopletoday? If writings from the period seem elevated consider that only thecream of the crop, so to speak, could read and write. If everyone inthe medieval period \"knew the rules\" it was a matter of uncriticallyaccepting what they were told.Bill Mayne   \n",
       "\n",
       "      target  \n",
       "0  christian  \n",
       "1  christian  \n",
       "2  christian  \n",
       "3  christian  \n",
       "4  christian  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "data[\"target\"] = data[\"target\"].apply(lambda target: \"altheism\" if target == 0 else \"christian\")\n",
    "data[\"text\"] = data[\"text\"].apply(lambda text: text.replace(\"\\n\", \"\"))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9b6ec410",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 2 elements, new values have 1 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [87]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext, target\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5588\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   5587\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 5588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   5590\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\properties.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:769\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m, labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m     labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:214\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\base.py:69\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 2 elements, new values have 1 elements"
     ]
    }
   ],
   "source": [
    "df.insert(0, 'New_ID', range(880, 880 + len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db8480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir_venv",
   "language": "python",
   "name": "ir_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
