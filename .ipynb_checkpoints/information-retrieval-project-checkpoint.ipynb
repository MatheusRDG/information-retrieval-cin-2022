{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8bdc85c",
   "metadata": {},
   "source": [
    "# Relatório e Projeto - Sistema de indexação e busca de documentos\n",
    "\n",
    "## 1 - Informações da equipe\n",
    "---\n",
    "IN1152 - Recuperação Inteligente de Informação - 2022.2\n",
    "\n",
    "**Dupla**: Matheus Rodrigues de Souza Félix (matheusrdgsf@gmail.com) e Rodrigo Souza de Melo (rsm5@cin.ufpe.br)\n",
    "\n",
    "**Projeto \"Sistema de indexação e busca de documentos\"**\n",
    "\n",
    "Professora Flavia de Almeida Barros (fab@cin.ufpe.br)\n",
    "\n",
    "- Este relatório apresentará as seções solicitadas no Trabalho 1 - Sistema de indexação e busca de documentos. E mais abaixo o código-fonte do projeto\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22b3ed4",
   "metadata": {},
   "source": [
    "## 2 - Descrição dos documentos (corpus) que serão indexados pelo sistema\n",
    "---\n",
    "\n",
    " - 2 Temas/tópicos dos documentos da sua base\n",
    " - Mostrar no relatório 2 ou 3 exemplos de documentos do corpus\n",
    " \n",
    " - BEIR [1] é um benchmark heterogêneo contendo diversas tarefas de RI. Ele também fornece uma estrutura comum e fácil para avaliação de seus modelos de recuperação baseados em PNL. Dentre as opções do BEIR foi selecionado o SciFact.\n",
    " - SciFact [4]: Devido ao rápido crescimento da literatura científica, há a necessidade de sistemas automatizados para auxiliar pesquisadores e o público na avaliação da veracidade das afirmações científicas. Para facilitar o desenvolvimento de sistemas para essa tarefa, é utilizado o SciFact, um conjunto de dados de 1,4 mil declarações escritas por especialistas, combinadas com resumos contendo evidências anotados com rótulos e justificativas de veracidade.\n",
    " - Leaderboard [4]: Avalia submissões de modelos no conjunto de dados SciFact, com o objetivo de desenvolver sistemas automatizados para verificação de alegações científicas.\n",
    " - Dataset [2]: Formando pelos elementos abaixo.\n",
    "   - corpus: Representa o título e o texto do documento\n",
    "   - query: Representa a consulta\n",
    "   - qrels: Representa a relevância das consulta(s) realizada(s)\n",
    "   \n",
    " - Exemplo de uma estrutura do documento com 2 queries, 2 documentos e as relevâncias de cada consulta [2].\n",
    "\n",
    "~~~json\n",
    "corpus = {\n",
    "    \"doc1\" : {\n",
    "        \"title\": \"Albert Einstein\", \n",
    "        \"text\": \"Albert Einstein was a German-born theoretical physicist. who developed the theory of relativity, \\\n",
    "                 one of the two pillars of modern physics (alongside quantum mechanics). His work is also known for \\\n",
    "                 its influence on the philosophy of science. He is best known to the general public for his massâ€“energy \\\n",
    "                 equivalence formula E = mc2, which has been dubbed 'the world's most famous equation'. He received the 1921 \\\n",
    "                 Nobel Prize in Physics 'for his services to theoretical physics, and especially for his discovery of the law \\\n",
    "                 of the photoelectric effect', a pivotal step in the development of quantum theory.\"\n",
    "        },\n",
    "    \"doc2\" : {\n",
    "        \"title\": \"\", # Keep title an empty string if not present\n",
    "        \"text\": \"Wheat beer is a top-fermented beer which is brewed with a large proportion of wheat relative to the amount of \\\n",
    "                 malted barley. The two main varieties are German WeiÃŸbier and Belgian witbier; other types include Lambic (made\\\n",
    "                 with wild yeast), Berliner Weisse (a cloudy, sour beer), and Gose (a sour, salty beer).\"\n",
    "    },\n",
    "}\n",
    "\n",
    "queries = {\n",
    "    \"q1\" : \"Who developed the mass-energy equivalence formula?\",\n",
    "    \"q2\" : \"Which beer is brewed with a large proportion of wheat?\"\n",
    "}\n",
    "\n",
    "qrels = {\n",
    "    \"q1\" : {\"doc1\": 1},\n",
    "    \"q2\" : {\"doc2\": 1},\n",
    "}\n",
    "~~~\n",
    " \n",
    " Referências: \n",
    " * [1] https://github.com/beir-cellar/beir\n",
    " * [2] https://huggingface.co/datasets/BeIR/scifact-generated-queries\n",
    " * [3] https://github.com/allenai/scifact\n",
    " * [4] https://leaderboard.allenai.org/scifact/submissions/about\n",
    "              \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ab8b7",
   "metadata": {},
   "source": [
    "## 3 - Arquitetura do sistema \n",
    "---\n",
    "\n",
    "- Prover uma descrição breve das etapas de processamento do sistema construído com base na ferramenta escolhida. Informar qual é o modelo de RI implementado pelo seu sistema, qual a fórmula para cálculo dos pesos e qual a função de ranking (vejam as aulas de modelos de RI). \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5cf095",
   "metadata": {},
   "source": [
    "## 4 - Criação das bases de documentos indexados \n",
    "---\n",
    "\n",
    "- Preparação & Indexação dos documentos: O sistema deve criar, de forma automática, cinco BASES indexadas a partir da base original de documentos. Cada BASE (no Solr, são COREs) deve utilizar processos diferentes na preparação (pré-processamento) dos dados. O objetivo é verificar qual é a melhor configuração de pré-processamento para o seu caso.\n",
    "\n",
    "   - BASE 1: documentos originais, sem nenhum pré-processamento extra (só tokenização);\n",
    "   - BASE 2: apenas eliminar stopwords (usar filtro de stopwords);\n",
    "   - BASE 3: apenas usar stemming, sem eliminar as stopwords (não usar filtro de stopwords);\n",
    "   - BASE 4: eliminar stopwords (usar filtro de stopwords) e usar stemming;\n",
    "   - BASE 5: eliminar stopwords (usar filtro de stopwords), não usar stemming, e usar dicionário de sinônimos.\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97192d6",
   "metadata": {},
   "source": [
    "## 5 - Criação das consultas e Criação da Matriz de relevância  \n",
    "---\n",
    "\n",
    "- Prover uma descrição breve das etapas de processamento do sistema construído com base na ferramenta escolhida. Informar qual é o modelo de RI implementado pelo seu sistema, qual a fórmula para cálculo dos pesos e qual a função de ranking (vejam as aulas de modelos de RI). \n",
    "\n",
    "- Esta etapa foi descrita em mais detalhes na atividade correspondente, postada no Classroom. \n",
    "  ===> DÚVIDA: NÃO ENCONTREI OS DETALHES NO CLASSROOM.\n",
    "  \n",
    "- Mostrar aqui parte da matriz - basta mostrar as 5 colunas exemplificadas abaixo (incluindo a coluna final com a quantidade de documentos relevantes). \n",
    "\n",
    "Exemplo de Matriz de relevância “Consultas x Documentos”.\n",
    "\n",
    "\n",
    "|                                                                      | Doc 1 | Doc 2 | ... Doc 20 | Qtd de docs relevantes |   |   |   |   |   |\n",
    "|----------------------------------------------------------------------|-------|-------|------------|------------------------|---|---|---|---|---|\n",
    "| Consulta1 Ex.:  como faço o agendamento para tomar vacina de covid ? | 1     | 0     | 1          | 10                     |   |   |   |   |   |\n",
    "| Consulta2 Ex.: Qual o preço de carro FIAT UNO usado ?                     | 1     | 1     | 0          | 15                     |   |   |   |   |   |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8025c9d6",
   "metadata": {},
   "source": [
    "## 6 - Testes/Avaliação \n",
    "---\n",
    "\n",
    "- Submeter as 2 consultas para cada BASE criada, e avaliar cada resultado separadamente -  i.e., calcular separadamente a precisão e a cobertura de cada consulta em relação a cada BASE criada. \n",
    "- Usar as fórmulas vistas em aula: precisão, cobertura e F-measure. \n",
    "- Incluir no relatório uma matriz de resultados para CADA consulta. Assim podemos ver a influência do pré-processamento dos documentos no resultado final do sistema.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Matriz de resultados para a Consulta 1\n",
    "- Consulta: incluam aqui o texto da consulta avaliada nessa matriz\n",
    "- Qtd de documentos relevantes: ver matriz de relevância (avaliação manual)\n",
    "\n",
    "|  | **Precisão** | **Cobertura** | **F-measure** | **Qtd de Docs relevantes retornados pela  consulta 1** | **Qtd total de documentos retornados pela consulta 1** |\n",
    "|:--------:|:------------:|:-------------:|:-------------:|:------------------------------------------------------:|:------------------------------------------------------:|\n",
    "| BASE 1   |              |               |               |                                                        |                                                        |\n",
    "| BASE 2   |              |               |               |                                                        |                                                        |\n",
    "| BASE 3   |              |               |               |                                                        |                                                        |\n",
    "| BASE 4   |              |               |               |                                                        |                                                        |\n",
    "| BASE 5   |              |               |               |                                                        |                                                        |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Matriz de resultados para a Consulta 2\n",
    "- Consulta: incluam aqui o texto da consulta avaliada nessa matriz\n",
    "- Qtd de documentos relevantes: ver matriz de relevância (avaliação manual)\n",
    "\n",
    "|  | **Precisão** | **Cobertura** | **F-measure** | **Qtd de Docs relevantes retornados pela  consulta 2** | **Qtd total de documentos retornados pela consulta 2** |\n",
    "|:--------:|:------------:|:-------------:|:-------------:|:------------------------------------------------------:|:------------------------------------------------------:|\n",
    "| BASE 1   |              |               |               |                                                        |                                                        |\n",
    "| BASE 2   |              |               |               |                                                        |                                                        |\n",
    "| BASE 3   |              |               |               |                                                        |                                                        |\n",
    "| BASE 4   |              |               |               |                                                        |                                                        |\n",
    "| BASE 5   |              |               |               |                                                        |                                                        |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Matriz de resultados para o Sistema\n",
    "- As medidas de precisão, cobertura e F-meause do sistema serão obtidas calculando-se a média entre os resultados obtidos com cada consulta em relação a cada BASE criado.\n",
    "\n",
    "\n",
    "|        | Precisão média | Cobertura média | F-measure média |\n",
    "|--------|----------------|-----------------|-----------------|\n",
    "| BASE 1 |                |                 |                 |\n",
    "| BASE 2 |                |                 |                 |\n",
    "| BASE 3 |                |                 |                 |\n",
    "| BASE 4 |                |                 |                 |\n",
    "| BASE 5 |                |                 |                 |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5d30e",
   "metadata": {},
   "source": [
    "## 7 - Conclusão \n",
    "---\n",
    "\n",
    "- Deve conter um texto curto explicando o que vocês concluíram a partir do resultado dos testes (tabelas acima).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb5cf0",
   "metadata": {},
   "source": [
    "## Código-fonte do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b2b07",
   "metadata": {},
   "source": [
    "### Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f60596e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GitPython\n",
      "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, gitdb, GitPython\n",
      "Successfully installed GitPython-3.1.27 gitdb-4.0.9 smmap-5.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install GitPython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea2a7b",
   "metadata": {},
   "source": [
    "### Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "acf48fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\marco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from git import Repo\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "import gzip\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report #Utilizado para calcular a matrix de confusão e Relatório de classificação - Checar outra forma para remover o warning e não utilizar o parâmetro zero_division=1 no recall_score \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import unidecode\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from scipy import spatial\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c323c7",
   "metadata": {},
   "source": [
    "### Data Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c8c1267",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"dataset/scifact-generated-queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ae5261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(DATA_PATH):\n",
    "    Repo.clone_from(\"https://huggingface.co/datasets/BeIR/scifact-generated-queries\", \"dataset/scifact-generated-queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9567a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(DATA_PATH+\"/train.jsonl.gz\", 'rb') as f:\n",
    "    file_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "408b3272",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json(BytesIO(file_content), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75057d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>queries_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHENIX: a comprehensive Python...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DNA methylation and healthy human aging</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US-SOMO HPLC-SAXS module: dealing with capill...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Grazing\": a high-risk behavior.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Natural\" killer cells in the mouse. I. Cytoto...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5176</th>\n",
       "      <td>β-catenin-independent WNT signaling in basal-l...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5177</th>\n",
       "      <td>β-site amyloid precursor protein-cleaving enzy...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>β1 integrin mediates an alternative survival p...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>‘Short stature in children - a questionnaire f...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5180</th>\n",
       "      <td>“Rapid-Impact Interventions”: How a Policy of ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5181 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  queries_count\n",
       "0                     PHENIX: a comprehensive Python...              3\n",
       "1               DNA methylation and healthy human aging              3\n",
       "2      US-SOMO HPLC-SAXS module: dealing with capill...              3\n",
       "3                      \"Grazing\": a high-risk behavior.              3\n",
       "4     \"Natural\" killer cells in the mouse. I. Cytoto...              3\n",
       "...                                                 ...            ...\n",
       "5176  β-catenin-independent WNT signaling in basal-l...              3\n",
       "5177  β-site amyloid precursor protein-cleaving enzy...              3\n",
       "5178  β1 integrin mediates an alternative survival p...              3\n",
       "5179  ‘Short stature in children - a questionnaire f...              3\n",
       "5180  “Rapid-Impact Interventions”: How a Policy of ...              3\n",
       "\n",
       "[5181 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby([\"title\"]).size().reset_index(name='queries_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c9b7f",
   "metadata": {},
   "source": [
    "## Pre-rocesing Data\n",
    "\n",
    "In this step we will create 5 data models:\n",
    "\n",
    "v1 - Only Tokenization; \\\n",
    "v2 - Only Stopword Filter; \\\n",
    "v3 - Only Stemming; \\\n",
    "v4 - Remove Stopwords and Stemming; \\\n",
    "v5 - Remove Stopworpd and expand words with Synonyms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a37629bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accent(text):\n",
    "    return unidecode.unidecode(text)\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text, language=\"english\")\n",
    "\n",
    "def pre_process(text, rmv_sw, stem):\n",
    "    text_lower = text.lower()\n",
    "    text_rmv_accent = remove_accent(text_lower)\n",
    "    text_final = tokenize(text_rmv_accent)\n",
    "    \n",
    "    if rmv_sw:\n",
    "        text_final = list(filter(lambda token: token not in STOPWORDS, text_final))\n",
    "    \n",
    "    if stem:\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        text_final = list(map(lambda token: stemmer.stem(token), text_final))\n",
    "        \n",
    "    return text_final\n",
    "\n",
    "STOPWORDS = set(map(lambda token: remove_accent(token), stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87c94be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process_v1 = lambda text: pre_process(text, False, False)\n",
    "pre_process_v2 = lambda text: pre_process(text, True, False)\n",
    "pre_process_v3 = lambda text: pre_process(text, False, True)\n",
    "pre_process_v4 = lambda text: pre_process(text, True, True)\n",
    "#pre_process_v5 = lambda i: pre_process(text, True, False) # TODO: Para este caso eu chequei esta referência -> https://www.holisticseo.digital/python-seo/nltk/wordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75283f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pcrs = dataset.copy().drop(\"query\", axis=1).drop_duplicates().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e714b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pcrs[\"v1\"] = dataset_pcrs[\"text\"].apply(lambda text: pre_process_v1(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "252a864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pcrs[\"v2\"] = dataset_pcrs[\"text\"].apply(lambda text: pre_process_v2(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91ab5f48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_pcrs[\"v3\"] = dataset_pcrs[\"text\"].apply(lambda text: pre_process_v3(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "517208ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pcrs[\"v4\"] = dataset_pcrs[\"text\"].apply(lambda text: pre_process_v4(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43c9b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO: Create Expand Vocabulary Pipeline add connect pre_process\n",
    "# dataset_pcrs[\"v5\"] = dataset_pcrs[\"text\"].apply(lambda text: pre_process_v5(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0c7d265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4983</td>\n",
       "      <td>Microstructural development of human newborn c...</td>\n",
       "      <td>Alterations of the architecture of cerebral wh...</td>\n",
       "      <td>[alterations, of, the, architecture, of, cereb...</td>\n",
       "      <td>[alterations, architecture, cerebral, white, m...</td>\n",
       "      <td>[alter, of, the, architectur, of, cerebr, whit...</td>\n",
       "      <td>[alter, architectur, cerebr, white, matter, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5836</td>\n",
       "      <td>Induction of myelodysplasia by myeloid-derived...</td>\n",
       "      <td>Myelodysplastic syndromes (MDS) are age-depend...</td>\n",
       "      <td>[myelodysplastic, syndromes, (, mds, ), are, a...</td>\n",
       "      <td>[myelodysplastic, syndromes, (, mds, ), age-de...</td>\n",
       "      <td>[myelodysplast, syndrom, (, mds, ), are, age-d...</td>\n",
       "      <td>[myelodysplast, syndrom, (, mds, ), age-depend...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _id                                              title  \\\n",
       "0  4983  Microstructural development of human newborn c...   \n",
       "3  5836  Induction of myelodysplasia by myeloid-derived...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Alterations of the architecture of cerebral wh...   \n",
       "3  Myelodysplastic syndromes (MDS) are age-depend...   \n",
       "\n",
       "                                                  v1  \\\n",
       "0  [alterations, of, the, architecture, of, cereb...   \n",
       "3  [myelodysplastic, syndromes, (, mds, ), are, a...   \n",
       "\n",
       "                                                  v2  \\\n",
       "0  [alterations, architecture, cerebral, white, m...   \n",
       "3  [myelodysplastic, syndromes, (, mds, ), age-de...   \n",
       "\n",
       "                                                  v3  \\\n",
       "0  [alter, of, the, architectur, of, cerebr, whit...   \n",
       "3  [myelodysplast, syndrom, (, mds, ), are, age-d...   \n",
       "\n",
       "                                                  v4  \n",
       "0  [alter, architectur, cerebr, white, matter, de...  \n",
       "3  [myelodysplast, syndrom, (, mds, ), age-depend...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Be careful with dataset_pcrs Len\n",
    "#HTML(dataset_pcrs.head(3).to_html())\n",
    "\n",
    "# @TODO: add \"()\" to STOPWORDS. A better strategy is create a dict simbol to filter and add this pipeline.\n",
    "dataset_pcrs.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489658fb",
   "metadata": {},
   "source": [
    "### Vectorizing Data\n",
    "\n",
    "This step defines 5 (vectorizer, corpus_vetorized) models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d182078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documments(df_column):\n",
    "    return list(map(lambda tokenized_text: \" \".join(tokenized_text), df_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57d9c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_v1 = get_documments(dataset_pcrs[\"v1\"])\n",
    "corpus_v2 = get_documments(dataset_pcrs[\"v2\"])\n",
    "corpus_v3 = get_documments(dataset_pcrs[\"v3\"])\n",
    "corpus_v4 = get_documments(dataset_pcrs[\"v4\"])\n",
    "# corpus_v5 = get_documments(dataset_pcrs[\"v5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8573ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_v1 = TfidfVectorizer()\n",
    "corpus_v1_vct = vectorizer_v1.fit_transform(corpus_v1)\n",
    "\n",
    "vectorizer_v2 = TfidfVectorizer()\n",
    "corpus_v2_vct = vectorizer_v2.fit_transform(corpus_v2)\n",
    "\n",
    "vectorizer_v3 = TfidfVectorizer()\n",
    "corpus_v3_vct = vectorizer_v3.fit_transform(corpus_v3)\n",
    "\n",
    "vectorizer_v4 = TfidfVectorizer()\n",
    "corpus_v4_vct = vectorizer_v4.fit_transform(corpus_v4)\n",
    "\n",
    "# vectorizer_v5 = TfidfVectorizer()\n",
    "# corpus_v1_vct = vectorizer_v5.fit_transform(corpus_v5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda70a07",
   "metadata": {},
   "source": [
    "### Retrieval Information Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c610c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kd -> KDTree, nn -> Nearest Neighbor, bf -> Brute Force\n",
    "# n -> number of docs in return, use -1 to all docs\n",
    "def info_retrieval(pre_process, corpus, vectorizer, query, n=2, matcher=\"kd\"):\n",
    "    \n",
    "    query = \" \".join(pre_process(query))\n",
    "    query_vct = vectorizer.transform([query])\n",
    "    \n",
    "    if n == -1:\n",
    "        \n",
    "        n = corpus.shape[0]\n",
    "    \n",
    "    if matcher == \"kd\":\n",
    "        \n",
    "        kdtree = scipy.spatial.KDTree(corpus_v1_vct.todense())\n",
    "        \n",
    "        # p is Minkowski p-norm.\n",
    "        # p = 1, Manhattan Distance\n",
    "        # p = 2, Euclidean Distance\n",
    "        # p = +inf, Chebychev Distance\n",
    "        distance, index = kdtree.query(query_vct.todense(), n, p=1)\n",
    "        \n",
    "    elif matcher == \"nn\":\n",
    "        \n",
    "        nbrs = NearestNeighbors(n_neighbors=n, algorithm=\"ball_tree\").fit(corpus)\n",
    "        distance, index = nbrs.kneighbors(query_vct)\n",
    "        \n",
    "    elif matcher == \"bf\":\n",
    "\n",
    "        nbrs = NearestNeighbors(n_neighbors=n, algorithm=\"brute\", metric=\"cosine\").fit(corpus)\n",
    "        distance, index = nbrs.kneighbors(query_vct)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        return \"Matcher strategy not avaliable. Set kd to KDTree, nn to Nearest Neighbor and bf to Brute Force\"\n",
    "    \n",
    "    return list(zip(distance.tolist()[0], index.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4383e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_v1 = lambda query: info_retrieval(pre_process_v1, corpus_v1_vct, vectorizer_v1, query, n=-1, matcher = \"bf\")\n",
    "ir_v2 = lambda query: info_retrieval(pre_process_v2, corpus_v2_vct, vectorizer_v2, query, n=-1, matcher = \"bf\")\n",
    "ir_v3 = lambda query: info_retrieval(pre_process_v3, corpus_v3_vct, vectorizer_v3, query, n=-1, matcher = \"bf\")\n",
    "ir_v4 = lambda query: info_retrieval(pre_process_v4, corpus_v4_vct, vectorizer_v4, query, n=-1, matcher = \"bf\")\n",
    "# ir_v5 = lambda query: info_retrieval(pre_process_v5, corpus_v5_vct, vectorizer_v5, query, n=-1, matcher = \"bf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590be1bc",
   "metadata": {},
   "source": [
    "### Snippet Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82e66307",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Alterations of the architecture of cerebral white matter in the developing human brain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb86c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sorted(ir_v1(query), key=lambda i:i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5357961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5512980389649619, 0),\n",
       " (0.9018937692186384, 4),\n",
       " (0.9030226639226278, 8),\n",
       " (0.904491849656119, 22),\n",
       " (0.9045364304922894, 3),\n",
       " (0.9055550155037727, 15),\n",
       " (0.9059548306703978, 40),\n",
       " (0.9107837002564602, 23),\n",
       " (0.9180953622326151, 7),\n",
       " (0.9188460324359904, 10),\n",
       " (0.9197344396945608, 37),\n",
       " (0.9204179861579849, 26),\n",
       " (0.9209788244798877, 47),\n",
       " (0.924605936837051, 34),\n",
       " (0.9257283763325889, 14),\n",
       " (0.9301273361039335, 46),\n",
       " (0.930343144950218, 20),\n",
       " (0.9307127649225015, 25),\n",
       " (0.9309219855750911, 36),\n",
       " (0.9310791524131075, 17),\n",
       " (0.9323432398604214, 21),\n",
       " (0.9333678935374439, 42),\n",
       " (0.9347401841822083, 30),\n",
       " (0.9375193526919786, 6),\n",
       " (0.9380836793410617, 24),\n",
       " (0.9438240485634083, 29),\n",
       " (0.9438526522441384, 33),\n",
       " (0.9448974986965711, 1),\n",
       " (0.9451534537521332, 31),\n",
       " (0.945777795071706, 27),\n",
       " (0.9465581953663532, 13),\n",
       " (0.9472385587498705, 45),\n",
       " (0.9495743997281749, 2),\n",
       " (0.9497327886616467, 5),\n",
       " (0.9499669994122191, 44),\n",
       " (0.950751768678862, 28),\n",
       " (0.9521823112364727, 32),\n",
       " (0.9523517911829948, 43),\n",
       " (0.9545493851186811, 41),\n",
       " (0.9546771015512568, 9),\n",
       " (0.9558180117821312, 11),\n",
       " (0.9559451637582027, 38),\n",
       " (0.9574216094551308, 35),\n",
       " (0.9603206219248321, 16),\n",
       " (0.9615924561868899, 39),\n",
       " (0.9639090554631371, 48),\n",
       " (0.9680065228057593, 49),\n",
       " (0.9696280094304914, 18),\n",
       " (0.9710623396735132, 12),\n",
       " (0.9714501756438524, 19)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cd70023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4983"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nearest Documment to Query Snippet\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "result_nn = result[0][1]\n",
    "dataset_pcrs[[\"_id\", \"title\", \"text\"]].iloc[[result_nn]][\"_id\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9692de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639f6be5",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cc4a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar Function to Get ID of nearest documment to specified query.\n",
    "def get_nearest_id(query, model, data):\n",
    "    result = sorted(model(query), key=lambda i:i[0])\n",
    "    result_nn = result[0][1]\n",
    "    return int(data[[\"_id\"]].iloc[[result_nn]][\"_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a6223e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>54440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>70115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>70490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>72159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>79447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>87758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>92308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>92499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>97884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>102662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>103007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>104130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>106301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>116792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>118568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>120626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>123859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>140874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>143251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>152245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>153744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>159469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>164189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>164985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>169264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>175735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>188911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>195352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>202259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>207972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>213017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>219475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>226488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>236204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>238409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>243694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>253672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>263364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>266641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>275294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>279052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>285794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>293661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        _id\n",
       "0      4983\n",
       "3      5836\n",
       "6      7912\n",
       "9     18670\n",
       "12    19238\n",
       "15    33370\n",
       "18    36474\n",
       "21    54440\n",
       "24    70115\n",
       "27    70490\n",
       "30    72159\n",
       "33    79447\n",
       "36    87758\n",
       "39    92308\n",
       "42    92499\n",
       "45    97884\n",
       "48   102662\n",
       "51   103007\n",
       "54   104130\n",
       "57   106301\n",
       "60   116792\n",
       "63   118568\n",
       "66   120626\n",
       "69   123859\n",
       "72   140874\n",
       "75   143251\n",
       "78   152245\n",
       "81   153744\n",
       "84   159469\n",
       "86   164189\n",
       "89   164985\n",
       "92   169264\n",
       "95   175735\n",
       "98   188911\n",
       "101  195352\n",
       "104  202259\n",
       "107  207972\n",
       "110  213017\n",
       "113  219475\n",
       "116  226488\n",
       "119  236204\n",
       "122  238409\n",
       "125  243694\n",
       "128  253672\n",
       "131  263364\n",
       "134  266641\n",
       "137  275294\n",
       "140  279052\n",
       "143  285794\n",
       "146  293661"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pcrs[[\"_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4d750e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used_ids -> flag if we used some batch in dataset_pcrs in development\n",
    "used_ids = dataset_pcrs[\"_id\"].tolist()\n",
    "ds_eval = dataset[dataset[\"_id\"].isin(used_ids)].drop([\"text\"], axis=1).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcca499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_eval[\"ir_v1_nn\"] = ds_eval[\"query\"].apply(lambda query: get_nearest_id(query, ir_v1, dataset_pcrs))\n",
    "ds_eval[\"ir_v2_nn\"] = ds_eval[\"query\"].apply(lambda query: get_nearest_id(query, ir_v2, dataset_pcrs))\n",
    "ds_eval[\"ir_v3_nn\"] = ds_eval[\"query\"].apply(lambda query: get_nearest_id(query, ir_v3, dataset_pcrs))\n",
    "ds_eval[\"ir_v4_nn\"] = ds_eval[\"query\"].apply(lambda query: get_nearest_id(query, ir_v4, dataset_pcrs))\n",
    "#ds_eval[\"ir_v5_nn\"] = ds_eval_v1[\"query\"].apply(lambda i: get_nearest_id(query, ir_v5, dataset_pcrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96b33648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>query</th>\n",
       "      <th>ir_v1_nn</th>\n",
       "      <th>ir_v2_nn</th>\n",
       "      <th>ir_v3_nn</th>\n",
       "      <th>ir_v4_nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4983</td>\n",
       "      <td>Microstructural development of human newborn c...</td>\n",
       "      <td>what is the diffusion coefficient of cerebral ...</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4983</td>\n",
       "      <td>Microstructural development of human newborn c...</td>\n",
       "      <td>what is diffusion tensor</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4983</td>\n",
       "      <td>Microstructural development of human newborn c...</td>\n",
       "      <td>what is the diffusion coefficient of the cereb...</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "      <td>4983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5836</td>\n",
       "      <td>Induction of myelodysplasia by myeloid-derived...</td>\n",
       "      <td>which type of hematopoiesis is characterized b...</td>\n",
       "      <td>5836</td>\n",
       "      <td>5836</td>\n",
       "      <td>5836</td>\n",
       "      <td>5836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5836</td>\n",
       "      <td>Induction of myelodysplasia by myeloid-derived...</td>\n",
       "      <td>which cell types have hematopoiesis</td>\n",
       "      <td>5836</td>\n",
       "      <td>5836</td>\n",
       "      <td>5836</td>\n",
       "      <td>5836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _id                                              title  \\\n",
       "0  4983  Microstructural development of human newborn c...   \n",
       "1  4983  Microstructural development of human newborn c...   \n",
       "2  4983  Microstructural development of human newborn c...   \n",
       "3  5836  Induction of myelodysplasia by myeloid-derived...   \n",
       "4  5836  Induction of myelodysplasia by myeloid-derived...   \n",
       "\n",
       "                                               query  ir_v1_nn  ir_v2_nn  \\\n",
       "0  what is the diffusion coefficient of cerebral ...      4983      4983   \n",
       "1                           what is diffusion tensor      4983      4983   \n",
       "2  what is the diffusion coefficient of the cereb...      4983      4983   \n",
       "3  which type of hematopoiesis is characterized b...      5836      5836   \n",
       "4                which cell types have hematopoiesis      5836      5836   \n",
       "\n",
       "   ir_v3_nn  ir_v4_nn  \n",
       "0      4983      4983  \n",
       "1      4983      4983  \n",
       "2      4983      4983  \n",
       "3      5836      5836  \n",
       "4      5836      5836  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_eval.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6db9fc88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# @TODO: add ir_v5_nn\n",
    "eval_models = {\"model\": [\"ir_v1_nn\",\"ir_v2_nn\",\"ir_v3_nn\",\"ir_v4_nn\"],\n",
    "               \"precision\": [], \"recall\": [], \"f-measure\": []}\n",
    "\n",
    "for model in eval_models[\"model\"]:\n",
    "    \n",
    "    y_true = list(map(lambda i: int(i), ds_eval[\"_id\"].tolist()))\n",
    "    y_pred = list(map(lambda i: int(i), ds_eval[model].tolist()))\n",
    "    \n",
    "    \n",
    "    eval_models[\"precision\"].append(precision_score(y_true, y_pred, average='weighted'))\n",
    "    \n",
    "    #Old\n",
    "    #eval_models[\"recall\"].append(recall_score(y_true, y_pred, average='weighted'))\n",
    "    #Test -> Mesmo removendo o warning, o resultado deu o mesmo ao imprimir o resultado dos métodos.\n",
    "    eval_models[\"recall\"].append(recall_score(y_true, y_pred, average='weighted', zero_division=1))\n",
    "    \n",
    "    eval_models[\"f-measure\"].append(f1_score(y_true, y_pred, average='weighted'))\n",
    "    \n",
    "    #Sugestão avaliar a matrix de confusão e o relatório de classificação para verificar como alterar o modelo.\n",
    "    # print(confusion_matrix(y_true,y_pred))\n",
    "    # print(classification_report(y_true,y_pred))\n",
    "    \n",
    "    '''\n",
    "    Alteração no código -> eval_models[\"recall\"].append(recall_score(y_true, y_pred, average='weighted', zero_division=1))\n",
    "         Foi apenas adicionado o parâmetro \"zero_division=1\"\n",
    "\n",
    "\n",
    "         Fonte: https://stackoverflow.com/questions/68534836/warning-precision-and-f-score-are-ill-defined-and-being-set-to-0-0-in-labels-wi\n",
    "                https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5b13fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(eval_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47db6661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f-measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ir_v1_nn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ir_v2_nn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ir_v3_nn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ir_v4_nn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  precision  recall  f-measure\n",
       "0  ir_v1_nn        1.0    1.00      1.000\n",
       "1  ir_v2_nn        1.0    1.00      1.000\n",
       "2  ir_v3_nn        1.0    0.96      0.976\n",
       "3  ir_v4_nn        1.0    0.96      0.976"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
